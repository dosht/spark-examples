{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val rawdata = sc.textFile(\"file:///docker/datasets/covtype.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg._\n",
    "import org.apache.spark.mllib.regression._\n",
    "\n",
    "val data = rawdata.map { line => \n",
    "    val values = line.split(\",\").map(_.toDouble)\n",
    "    val features = Vectors.dense(values.init)\n",
    "    val label = values.last - 1\n",
    "    LabeledPoint(label, features)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[6] at randomSplit at <console>:24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(trData, cvData, teData) = data.randomSplit(Array(0.8, 0.1, 0.1))\n",
    "trData.cache()\n",
    "cvData.cache()\n",
    "teData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.tree._\n",
    "\n",
    "val treeModel = DecisionTree.trainClassifier(trData, 7, Map[Int, Int](), \"gini\", 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.evaluation._\n",
    "import org.apache.spark.mllib.tree._\n",
    "import org.apache.spark.mllib.tree.model._\n",
    "\n",
    "val predectionsAndLabels = teData.map(ex => treeModel.predict(ex.features) -> ex.label)\n",
    "val metric = new MulticlassMetrics(predectionsAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric.confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric.precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(1 until 7) map (cat => metric.precision(cat) -> metric.recall(cat)) foreach println"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate random guessing threashold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "def classProbabilities(data: RDD[LabeledPoint]): Array[Double] = {\n",
    "    val countsByClass = data.map(_.label).countByValue\n",
    "    val counts = data.map(_.label).countByValue.values.toArray.sorted\n",
    "    counts.map(_.toDouble / counts.sum)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(classProbabilities(trData) zip classProbabilities(cvData)).map {\n",
    "    case (trainProb, cvProb) => trainProb * cvProb\n",
    "}.sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.evaluation._\n",
    "import org.apache.spark.mllib.tree._\n",
    "import org.apache.spark.mllib.tree.model._\n",
    "\n",
    "val evaluations = for {\n",
    "    impurity <- Array(\"gini\", \"entropy\")\n",
    "    depth <- Array(1, 20)\n",
    "    bins <- Array(10, 300)\n",
    "} yield {\n",
    "    val model = DecisionTree.trainClassifier(trData, 7, Map[Int, Int](), impurity, depth, bins)\n",
    "    val predictionsAndLabels = cvData.map(ex => (model.predict(ex.features) -> ex.label))\n",
    "    val accuracy = new MulticlassMetrics(predictionsAndLabels).precision\n",
    "    ((impurity, depth, bins), accuracy)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val forest = RandomForest.trainClassifier(trData, 7, Map(10 -> 4, 11 -> 40), 20, \"auto\", \"entropy\", 30, 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10.4 (Spark 1.4.1)",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
