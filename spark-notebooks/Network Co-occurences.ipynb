{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached version of common-1.0.2-jar-with-dependencies.jar\n"
     ]
    }
   ],
   "source": [
    "%addJar file:/docker/lib/common-1.0.2-jar-with-dependencies.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import com.cloudera.datascience.common.XmlInputFormat\n",
    "import org.apache.hadoop.io.{ Text, LongWritable }\n",
    "import org.apache.hadoop.conf.Configuration\n",
    "\n",
    "val path = \"/docker/datasets/medline\"\n",
    "@transient val conf = new Configuration()\n",
    "conf.set(XmlInputFormat.START_TAG_KEY, \"<MedlineCitation \")\n",
    "conf.set(XmlInputFormat.END_TAG_KEY, \"</MedlineCitation>\")\n",
    "val in = sc.newAPIHadoopFile(path, classOf[XmlInputFormat], classOf[LongWritable], classOf[Text], conf)//.sample(false, 0.0001)\n",
    "val rawRdd = in.map(line => line._2.toString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(Computer Simulation, Models, Cardiovascular)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.xml.{ XML, Elem }\n",
    "def majorTopics(elem: Elem): Seq[String] = {\n",
    "    val dn = elem \\\\ \"DescriptorName\"\n",
    "    val mt = dn.filter(n => (n \\ \"@MajorTopicYN\").text == \"Y\")\n",
    "    mt.map(n => n.text)\n",
    "}\n",
    "\n",
    "val xmlRdd = rawRdd.map(XML.loadString)\n",
    "val medline = xmlRdd.map(majorTopics).filter(_.nonEmpty).cache()\n",
    "medline.take(1)(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15154\n",
      "(Research,3094)\n",
      "(Disease,2692)\n",
      "(Neoplasms,1891)\n",
      "(Public Policy,1620)\n",
      "(Jurisprudence,1595)\n",
      "(Demography,1524)\n",
      "(Population Dynamics,1502)\n",
      "(Economics,1382)\n",
      "(Socioeconomic Factors,1299)\n",
      "(Blood,1264)\n"
     ]
    }
   ],
   "source": [
    "val topics = medline.flatMap(x => x)\n",
    "println(topics.distinct.count)\n",
    "topics.countByValue.toSeq.sortBy(- _._2).take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hash(x: Any) = x.##.toLong\n",
    "val vertices = topics.map(topic => hash(topic) -> topic)\n",
    "vertices.map(_._1).countByValue.size == vertices.map(_._2).countByValue.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229601"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val topicPairs = medline.flatMap(t => t.sorted.combinations(2))\n",
    "val cooccurs = topicPairs.map(p => p -> 1).reduceByKey(_ + _)\n",
    "cooccurs.cache()\n",
    "cooccurs.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.graphx._\n",
    "\n",
    "val edges = cooccurs.map { p =>\n",
    "    val (topics, cnt) = p\n",
    "    val ids = topics.map(hash).sorted\n",
    "    Edge(ids(0), ids(1), cnt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val topicGraph = Graph(vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArrayBuffer((-2146994723,14132), (-2117711008,5), (-1780068791,4), (-1884199532,3), (-770162488,3), (-833189025,3), (-1749011714,3), (-1347759196,3), (-1269853108,3), (-1173222909,3), (349631822,2), (-248503704,2), (694941816,2), (1004812845,2), (-1125835952,2), (1149468248,2), (-188604902,2), (1251460648,2), (-1660541797,2), (-2018435056,2), (511639598,2), (-593879031,2), (890492431,2), (-594015880,2), (-1679655020,2), (-1909316450,2), (-1455963424,2), (-605701197,2), (-235746564,2), (-1928601699,2), (389444582,2), (-1884527612,2), (-1509934809,2), (752675843,2), (-1006799626,2), (-1369445892,2), (-240632659,2), (373043352,2), (-749871690,2), (-265065099,2), (-1865475570,2), (-976690972,2), (-1034421687,2), (250501833,2), (-3388462..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val connectedComponents = topicGraph.connectedComponents\n",
    "val componentCounts = connectedComponents.vertices.map(_._2).countByValue.toSeq.sortBy(- _._2)\n",
    "componentCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10.4 (Spark 1.5.2)",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
